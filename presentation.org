#    -*- mode: org -*-
#+OPTIONS: reveal_center:t reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_mathjax:t reveal_rolling_links:nil reveal_keyboard:t reveal_overview:t num:nil
#+OPTIONS: reveal_width:1600 reveal_height:900
#+OPTIONS: tex:t toc:nil <:nil timestamp:nil email:t reveal_slide_number:"c/t"
#+REVEAL_MARGIN: 0.1
#+REVEAL_MIN_SCALE: 0.5
#+REVEAL_MAX_SCALE: 2.5
#+REVEAL_TRANS: none
#+REVEAL_THEME: blood
#+REVEAL_HLEVEL: 1
#+REVEAL_EXTRA_CSS: ./presentation.css
#+REVEAL_ROOT: ../reveal.js/

#+TITLE: Identifying Monoids
#+AUTHOR: Ben Deane
#+EMAIL: bdeane@quantlab.com
#+DATE: May 2019

# +REVEAL_HTML: <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
#+REVEAL_HTML: <script type="text/javascript" src="./presentation.js"></script>

* Title slide settings                                             :noexport:
#+BEGIN_SRC emacs-lisp
(setq org-re-reveal-title-slide
(concat "<h2>%t</h2>"
"<h3>Exploiting Compositional Structure in Code</h3>"
"<div class='vertspace2'></div>"
"<img src=\"./wood.png\"/>"
"<p>\\(\\left \\{ \\mathbb{Z}, \\times, 1 \\right \\}\\)</p>"
"<div class='vertspace2'></div>"
"<h4>%a / <a href=\"http://twitter.com/ben_deane\">@ben_deane</a>"
" / C++Now / Aspen, CO / %d</h4>"))
#+END_SRC

* Introduction

** Let's get this out of the way.

#+REVEAL_HTML: <div class='vertspace2'></div>
A monoid is NOT the same thing as a monad.

#+begin_notes
Some of you already know this. (How many people know all about monoids?)

Some people, online or wherever, may be confused, so I wanted to be clear.

This isn't a talk with a lot of category theory. I'm probably going to say lots
of things that mathematicians will take issue with. I'm going to try ground this
talk in examples.
#+end_notes

** Why

Why are monoids important?

Why is "abstract mathematics" important for programming?

#+begin_notes
(Tell the Simeon story.)

There are people who think this kind of mathematics has no place in programming.
(They don't seem to mind other kinds of maths like linear algebra.) They are
looking at things the wrong way.

When we program, we're doing maths whether we know it or not, and it helps us to
realize that. Composition is the essence of programming architecture. Abstract
algebra is the framework for ideas of composition.

You can program without maths, just like you can bake without knowing chemistry.
But you're doing it anyway. You already have an intuition for it.

Abstract algebra is to programming what calculus is to modelling the real world.
#+end_notes

** A quick code review

#+begin_src c++
void RepositionListItem(int drag_start_idx, int drop_idx) {
  // grab the dragged item
  Item* item = list_items_[drag_start_index];

  // move the rest down
  for (auto i = drag_start_idx + 1; i < list_items_.size(); ++i) {
    list_items_[i-1] = list_items_[i];
  }
  list_items_.pop_back();

  // re-insert the item ("drop" it)
  list_items_.insert(item, list_items_.begin() + drop_idx);
}
#+end_src

#+ATTR_REVEAL: :frag (appear)
 - "This is (obviously?) a rotate."
 - And there's a bug here. Is ~drag_start_idx~ ~>~ ~drop_idx~?

#+begin_notes
What would you suggest for this code review?

What is this code doing?

Do you see any problems?
#+end_notes

** How did we know that?

Expertise.

 - Hard to say how
 - Difference in perception
   - Selectivity of attention
   - Units of perception
   - Unconscious search strategies
 - Speed of processing

#+begin_notes
These are the hallmarks of expertise. A difference in what we pay attention to.
A difference in the chunk size of things we perceive. A difference in the search
patterns we pursue. And a huge speed difference.

Everyone here is a C++ expert. We probably can't really explain how we knew the
problems. You just had a "spidey sense". A C++ novice looking at the code may
not even know where to begin.
#+end_notes

** How brains work

1. See lots of examples with lots of variation. Some variation is relevant,
   some is not.
1. Figure out which variation is relevant, and classify.
1. Trial and error: rinse, repeat...
1. Result after time: "instinctual" expertise

#+ATTR_REVEAL: :frag (appear)
So let's get going.

#+begin_notes
We can say how we got here, because this is what brains do. We don't learn by
applying abstract rules. We learn by this process.

So in this talk, mostly I'm going to show lots of different monoids, so that we
get an intuition about how to recognize them; each brain experiencing this talk
will form its own pattern-recognition pathways. This is what brains do (very
well).

When we have that sense, then it can be useful to fill in more theory.
#+end_notes

** What is a monoid?

A set of values.
 - finite or infinite

A binary operation.
 - closed
 - associative

One special value in the set.
 - the identity

#+begin_notes
Before I show examples, here is some context to understand them.
#+end_notes

* Motivation

#+REVEAL_HTML: <div class='vertspace2'></div>
(In response to post-talk questions about how to "identify your monoids")
#+REVEAL_HTML: <div class='vertspace2'></div>

#+REVEAL_HTML: <blockquote nil><p>&quot;As a writer of a library, or code that someone else will use,<br>
#+REVEAL_HTML: identifying monoids in your code -- in your types and your<br>
#+REVEAL_HTML: operations -- I think is one of the single biggest things<br>
#+REVEAL_HTML: you can do to help users of your library.&quot;</p>
#+REVEAL_HTML: <div></div><div class='author'>-- me, <em>Easy to Use, Hard to Misuse: Declarative Style in C++</em></div></blockquote>

#+begin_notes
It's also one of the best things you can do to help your own thinking about
library architecture and the macro structure of your code.
#+end_notes

** Why is it important to recognize them?

Architecture.
A means to talk about what's happening in our code.

It's not about functional programming, it's not about abstraction for its own
sake.

Computational sympathy.

** Abstraction

"Being abstract is something profoundly different from being vague... the purpose
of abstraction is not to be vague, but to create a new semantic level in which
one can be absolutely precise."

--EWD

** Design Patterns

Compare Design Patterns.

There are people who get the wrong end of the stick about this. There are people
who, for example, tweet that they're hiring, but say things like "use of Design
Patterns is a negative".

Design Patterns came out in 1995. The implementations in it are of their time.
They represent a Java-style, late 90s, heavy-OO, dynamic dispatch style of
implementation. That's not the lasting legacy of the book.

If we're talking about code and I say to you, "I think we could solve this with
a visitor pattern", I'm not saying "let's open the Gang of Four book and
implement all this machinery to implement dynamic double-dispatch." I'm saying
"I think we could benefit from the ability to easily add behaviours over types."
And we can implement that using all the tools we have in our toolbox and make it
perform arbitrarily well according to our needs.

** The power of abstraction

We can talk about our code's needs rather than how to implement those needs

** Late night coding with Simeon

You only have a binary operation to combine objects
You have a list of objects to combine
Show a raw loop
Realize it's an accumulate - we have a monoid!

** Alex Stepanov

Saw/realised the structure of monoids/semigroups while sick

** Why?

When we recognize monoids, we gain the ability to separate concerns.

If we write code as raw loops, we commingle the business logic with the code
that handles control flow.

Instead of having to learn anew how each computation in our code works, a user
of our code/library just has to learn one idea: that of accumulation. They don't
have to puzzle out what each loop is doing.


* Examples

#+REVEAL_HTML: <div class='vertspace2'></div>
We'll start with the obvious ones

** The Obvious Monoids
#+REVEAL_HTML: <div class='vertspace2'></div>

There's a reason why the default operation of ~accumulate~ is addition.

#+REVEAL_HTML: <div class='vertspace2'></div>

 - \( \left \{ \mathbb{R}, +, 0 \right \} \)
 - \( \left \{ \mathbb{R}, \times, 1 \right \} \)

#+REVEAL_HTML: <div class='vertspace2'></div>

For \(\mathbb{R}\), read also \(\mathbb{Z}\) or \(\mathbb{N}\). (And also
\(\mathbb{C}\)).

#+begin_notes
A grade school child can understand monoids. Notice the three properties:

 - closed operation (it's so obvious with these examples, but it's really important
as we shall see later)
 - associativity: it doesn't matter how we group them
 - there is an identity (and only one)

Notice these are commutative, but commutativity is not required.
#+end_notes

** Addition & Multiplication
#+REVEAL_HTML: <div class='vertspace2'></div>

Cover many things that are "number-like".

 - integers (approximated by ~int~ etc)
 - real numbers (approximated by ~float~ or ~double~)
 - complex numbers
 - vectors (in the mathematical sense)
 - matrices

We can use (almost) any of these with ~accumulate~ (or fold expressions)\\
and ~plus~ or ~multiplies~.

#+begin_notes
In C++ of course, we normally approximate all these things with finite datatypes.

A complex number is just a pair in the complex plane with memberwise addition.
Recall for multiplication we multiply the magnitudes (moduli) and sum the angles
(arguments). The identity is therefore (1, 0).

For vectors we can do memberwise addition, but we can't do multiplication: the
dot product isn't closed, and the cross product has no identity since it always
produces a vector perpendicular to the two inputs.

Matrix addition is memberwise. Note matrix multiplication isn't commutative.
#+end_notes

** ~min~ and ~max~
#+REVEAL_HTML: <div class='vertspace2'></div>

It's clear that ~max~ is a monoid on positive numbers:

\( \left \{ \mathbb{Z^+}, max, 0 \right \} \)

#+REVEAL_HTML: <div class='vertspace2'></div>

~min~ is less clear mathematically...

\( \left \{ \mathbb{Z}, min, ? \right \} \)

... but we can often use ~numeric_limits<T>::max~ as the identity.

#+begin_notes
Again for Z, read "anything numeric".

Mirror situations apply for dealing with negative numbers.
#+end_notes

** Boolean values: AND and OR
#+REVEAL_HTML: <div class='vertspace2'></div>
 \( \left \{ \{true, false\}, \land, true \right \} \)
#+begin_src c++
template <typename... Args>
bool all(Args&&... args) { return (... && args); }
#+end_src

#+REVEAL_HTML: <div class='vertspace2'></div>
 \( \left \{ \{true, false\}, \lor, false \right \} \)
#+begin_src c++
template <typename... Args>
bool any(Args&&... args) { return (... || args); }
#+end_src

#+begin_notes
C++ allows us to use logical AND and logical OR in unary folds.

The value for an empty pack with AND is ~true~.

The value for an empty pack with OR is ~false~.
#+end_notes

** Boolean values: XOR
#+REVEAL_HTML: <div class='vertspace2'></div>
\( \left \{ \{true, false\}, \oplus, false \right \} \)

| A       | B       | Result  |
|---------+---------+---------|
| ~false~ | ~false~ | ~false~ |
| ~false~ | ~true~  | ~true~  |
| ~true~  | ~false~ | ~true~  |
| ~true~  | ~true~  | ~false~ |

#+REVEAL_HTML: <div class='vertspace2'></div>
Note: exclusive-or on ~bool~ is ~operator!=~

#+begin_notes
For XOR, the identity is ~false~ as we can see from the truth table.

In C++, we don't have logical XOR (~^^~?) but we do have bitwise XOR.
#+end_notes

* Code Interlude

#+REVEAL_HTML: <div class='vertspace2'></div>
Recognizing accumulation-style algorithms

** Code: the obvious algorithms
#+REVEAL_HTML: <div class='vertspace2'></div>

The following algorithms are almost a dead giveaway:

 - ~accumulate~, ~reduce~
 - basically, all the algorithms in ~<numeric>~
 - fold expressions

** ~<algorithm>~: the other "usual suspects"
#+REVEAL_HTML: <div class='vertspace2'></div>

Suspect a monoid whenever you find yourself using the following algorithms:

 - ~all_of~, ~any_of~, ~none_of~
 - (therefore also ~find~ and friends)
 - ~min_element~, ~max_element~, ~minmax_element~
 - ~count~, ~count_if~

#+begin_notes
#+end_notes

** Useful reformulations of ~accumulate~
#+REVEAL_HTML: <div class='vertspace2'></div>

#+begin_src c++
template <class InputIt, class Size, class T, class BinaryOp>
constexpr auto accumulate_n(InputIt first, Size n, T init, BinaryOp op)
    -> std::pair<T, InputIt> {
  for (; n > 0; --n, ++first) {
    init = op(std::move(init), *first);
  }
  return {init, first};
}
#+end_src

The standard library has some ~*_n~ algorithms; it should have more.

#+begin_notes
Note the principle of useful return here: we also return the iterator we've
reached.

Basically all the algorithms in the standard library should be available in two
forms: iterator-pair form and iterator, count form.

This idea is in EoP: some algorithms may be more efficient in the count form or
may provide more useful building blocks in that form.

I've used this in sliding-window type calculations, where you know the size of
the window.
#+end_notes

** Useful reformulations of ~accumulate~
#+REVEAL_HTML: <div class='vertspace2'></div>

#+begin_src c++
template <class InputIt, class T, class BinaryOp>
constexpr T accumulate_iter(InputIt first, InputIt last, T init, BinaryOp op) {
  for (; first != last; ++first) {
    init = op(std::move(init), first);
  }
  return init;
}
#+end_src

Pass the iterator to the ~op~ /undereferenced/.

#+begin_notes
The only difference here from the standard ~accumulate~ is the absence of a ~*~.
This is a formulation of ~accumulate~ that I used for the code experiments in my
2016 talk "accumulate: Exploring an Algorithmic Empire".

In C++2014 there were 90 standard algorithms. Using this formulation of
accumulate and some jiggery-pokery I was able to implement 77 of them.
#+end_notes

* More Examples

#+REVEAL_HTML: <div class='vertspace2'></div>
Because brains learn by seeing lots of variations.

** Strings
#+REVEAL_HTML: <div class='vertspace2'></div>

 - ~string~
 - ~operator+~ (concatenation)
 - empty string

#+REVEAL_HTML: <div class='vertspace2'></div>
Strings form a monoid under concatenation.\\
The identity is the empty string.

#+begin_notes
This is sometimes called "the free monoid". Note that it's not commutative. It's
"free" in the sense that it's the "generic" monoid with only the basic rules and
no other structure applied.
#+end_notes

** String-ish applications
#+REVEAL_HTML: <div class='vertspace2'></div>

#+begin_src c++
std::vector<T> v{1, 2, 3, 4, 5};

std::accumulate(
    std::cbegin(v), std::cend(v), std::ref(std::cout),
    [](auto &os, auto &elem) -> decltype(auto) { return os.get() << elem; });
#+end_src

Here, ~cout~ is acting like the accumulating string.

#+begin_notes
The actual code is making some concessions to performance. We can't just write
(string + string + string...) because we don't have efficient ways to look
through the copying of strings.

But I like to think about this in a way that highlights the monoidal structure.
What's really happening is that we're using a projection function on elements to
turn them into strings, and then we're accumulating a string in the world.
#+end_notes

** String-ish applications
#+REVEAL_HTML: <div class='vertspace2'></div>

#+begin_src c++
std::string url_base = "https://example.com/?";
std::map<std::string, std::string> url_args {{"alpha", "able"},
                                             {"bravo", "baker"}};

join(std::cbegin(url_args), std::cend(url_args),
     std::back_inserter(url_base), '&',
     [] (const auto& p) {
       const auto& [key, val] = p;
       return key + '=' + val;
     });
#+end_src

We accumulate the query arguments into the url.

** Joining string-ish things

#+begin_src c++
template <typename InputIt, typename OutputIt, typename T, typename Projection>
OutputIt join(InputIt first, InputIt last,
              OutputIt dest,
              const T& delimiter,
              Projection&& proj);
#+end_src

See also: ~std::experimental::ostream_joiner~, ~ranges::view::join~.

#+begin_notes
With ranges we can also pipe through a projection function quite easily. The
monoidal structure of the code becomes a bit clearer, because the range
machinery provides that lazy conversion.
#+end_notes

** Animations: a study in composing monoids

Consider an animation library.

What is an animation?
 - a series of keyframes?
 - a series of blends (curves?) between them?
 - a function from time to position?

How can we compose animations?
 - by pointwise operation
 - by sequencing

#+begin_notes
Let's take what we've seen so far and do a thought experiment: how could we
design API elements for an animation library?

Think about 1D animation to make it simple.

Compose by operation: any monoidal operation! Recall: recognize monoids by
thinking about what the identity is. (In this case the same-length animation
that is all "zeroes").

Compose by sequencing: like a string. Again, the identity is the zero-length
animation.
#+end_notes

* Going further

#+REVEAL_HTML: <div class='vertspace2'></div>
We've seen:
 - "primitive" monoids (on "number-like" things)
 - the free monoid (concatenation)

#+REVEAL_HTML: <div class='vertspace2'></div>
Let's look at composition.

** Containers
#+REVEAL_HTML: <div class='vertspace2'></div>

[[./pointwise_vector.svg]]

#+REVEAL_HTML: <div class='vertspace2'></div>
A container is a monoid on its ~value_type~.

#+begin_notes
Imagine having two maps that you want to combine.

In the first map, a key has a given value. In the second map, the same key has
another value. To combine the maps, we can apply the monoid operation on the two
values to get the resultant mapped value in the output.
#+end_notes

** Maps
#+REVEAL_HTML: <div class='vertspace2'></div>
A ~map~ is a monoid on its ~mapped_type~.

#+begin_src c++
std::map<std::string, int> jan_hours{{"Alice", 80},
                                     {"Bob", 90}};
std::map<std::string, int> feb_hours{{"Bob", 90},
                                     {"Charlie", 70}};

std::map<std::string, int> total_hours = ...;
// {"Alice", 80}, {"Bob", 180}, {"Charlie", 70}
#+end_src

#+begin_notes
It's easy to see how to compose maps where the keys are the same.

Notice the importance of the identity here: Alice worked the identity number of
hours in Feb, Charlie worked the identity number of hours in Jan.

If we didn't have an identity, this wouldn't work.
#+end_notes

** Product types: memberwise monoidal
#+REVEAL_HTML: <div class='vertspace2'></div>
~struct~, ~pair~, ~tuple~

#+begin_src c++
using modulus_t = double;
using argument_t = double;
using polar_complex_number_t = std::pair<modulus_t, argument_t>;

using computation_t = auto (*) (int) -> int;
using profile_data_t = std::pair<computation_t, chrono::nanoseconds>;
#+end_src

#+begin_notes
Two examples here: the first shows a pair of the same type where the monoidal
operation is different. (Consider complex number multiplication.)

The second shows two differenty types, so necessarily the monoids are different.
Here the monoid for the function could be composition (more on that later), and
the monoid for the profiled time is addition.
#+end_notes

** Sets
#+REVEAL_HTML: <div class='vertspace2'></div>
(Mathematical) sets are monoidal in another way: by intersection and union.

#+REVEAL_HTML: <div class='vertspace2'></div>
\( \left \{ \{sets\}, \cup, \varnothing \right \} \)

\( \left \{ \{sets\}, \cap, \mathbb{U} \right \} \)

#+begin_notes
The empty set is usually easy to code.

The universe (all possible sets) is usually more difficult...
#+end_notes

** Functions
#+REVEAL_HTML: <div class='vertspace2'></div>
If functions are pure, we can think of them as maps from inputs to outputs.

#+REVEAL_HTML: <div class='vertspace2'></div>
So functions are monoids on their outputs, like maps are monoids on their
~mapped_type~.

* Code Interlude

#+REVEAL_HTML: <div class='vertspace2'></div>
Identity problems.

** Value type problems
#+REVEAL_HTML: <div class='vertspace2'></div>
Usually we would want an identity to be provided by a type's default
constructor.

But sometimes, there is no good identity.

#+begin_src c++
struct color { ... };
#+end_src

Usually for one of two reasons:
 - real-world values don't have defaults
 - different identities are required for different operations

#+begin_notes
Often occurs in values representing things in the real world.

Clue to this: no good value choice for a default constructor.

Or: identity depends on operation, and default construction only has one
implementation.

This is a surmountable problem. You could use for example traits classes.
#+end_notes

** Identity problems
#+REVEAL_HTML: <div class='vertspace2'></div>
Sometimes, an operation is closed and associative, but really has no identity.

#+REVEAL_HTML: <div class='vertspace2'></div>
Or, your datatype might not be able to express the identity. (You crafted it
that way for safety in other areas.)

#+REVEAL_HTML: <div class='vertspace2'></div>
What to do?

#+begin_notes
This is a more serious problem. The second case is perhaps more likely.

We generally want to use strong types safely. It is often the case that an
identity is some kind of sentinel value like a null pointer or an empty string,
and you don't want to deal with it in most of the code.

Sometimes you just want to use that identity value in one place where you want
the monoidal property.
#+end_notes

** ~std::optional~ to the rescue
#+REVEAL_HTML: <div class='vertspace2'></div>
Providing a sentinel value that you can use as an identity is what
~std::optional~ does.

#+begin_src c++
template <typename Operation, typename T>
auto monoid_op = [](const std::optional<T>& x, const std::optional<T>& y)
    -> std::optional<T> {
  if (x == std::nullopt) return y;
  if (y == std::nullopt) return x;

  return Operation{}(*x, *y);
};
#+end_src

* Sets and Maps

Monoids on their value types

* Structs, pairs and tuples

Product types are monoidal if their constituents are
This is useful for accumulating effects
cf. Writer monad
http://blog.sigfpe.com/2009/01/haskell-monoids-and-their-uses.html

* Functions

Monoidal on their outputs
cf. maps

* Tree structures

"Normal" monoids have two operations:
 - one for combining with identity
 - one for combining with value

If we look at a tree structure as a sum type, we can extend this to:
 - one for combining each type of value

And we can run functions over tree structures, accumulating the values. Just
like std::accumulate, this gives us the power to separate the meaning of what
we're doing from the control flow of how we're doing it.

Most of the algorithms in the STL deal with linear sequences. And that's most of
what we handle. But quite often we handle treelike structures. It's much more
likely then that we'll fail to see the essential computation that's going on and
fall back on a raw loop because we think algorithms can't deal with what we're
doing. If we think in terms of monoids, we can get that separation of control
flow from logic and we can often use an accumulate-like algorithm to separate
the control flow.

* Endofunctions

Functions from A to A
Processes evolving in time
std::iota
std::iterate
ranges

Examples:

 - Eller's algo for maze generation - plain std::accumulate (linear data dependence)
   or partial_sum for intermediate output (good range example?)

 - RNG - LCG is a linear recurrence relation f :: a -> a
   represent as a matrix -> function composition is raising to nth power (log n)
   can "fast forward" RNG in log time because it's a monoid
https://www.nayuki.io/page/fast-skipping-in-a-linear-congruential-generator

Research:

https://meetingcpp.com/blog/items/ranges-for-numerical-problems-402.html
https://www.youtube.com/watch?v=13r9QY6cmjc
http://people.math.gatech.edu/~ecroot/recurrence_notes2.pdf

* Futures

when_any and never
UI applications

* Stronger than monoids
Commutativity
Existence of an inverse

* Accumulate vs reduce

Reduce requires commutativity for vectorization
Data-level parallelism at war with function-level parallelism
(parallelism vs concurrency)

* Balanced reduction

* Incremental computation

* Bigger applications

** Serialization
Monoid-like, but with varying types

** Profiling
Another kind of serialization

** Statistics
Keeping a mean
Keeping a median
Top n
Histograms

** Probabilistic algorithms
"Fantastic algorithms and where to find them"
"Add ALL the things!"

Hyperloglog
Count min-sketch

** Config

JSON objects, databases, configuration blobs, sets of command-line flags
Protocol buffers

We "reinvent" monoids all the time without realizing it! Most of the time when
we deal with these kinds of things, we don't think about their monoidal nature.

https://mail.haskell.org/pipermail/haskell-cafe/2009-January/053709.html

** Parsers

Parsers are monoids under alternation. The identity is the parser that always
fails. This is a common pattern if you have an operation that can fail.

cf. when_any
cf. optional

** Monoid homomorphisms

A function that preserves the monoid structure. If A and B are monoids under
some operations, then f :: A -> B is a monoid homomorphism if it preserves the
structure.

e.g.
 - strings are monoids under concatenation.
 - integers are monoids under addition.

string length is a monoid homomorphism.

** Why use monoid homomorphisms?

- to get into a space that is easier to reason about
- to be able to do more
- for performance
- all of the above

** For perf?

We're always doing things for performance reasons of course.
We're often computing things in a "different space" for perf reasons.

e.g.

In vector spaces, we can avoid square roots when computing magnitudes because we
can compare to a precomputed magnitude in "squared space" instead.

In vector spaces, we measure angles between vectors by comparing with
precomputed cosine constants rather than doing an inverse trig function.

** Ofuscated example

#+begin_src c
main(n){float r,i,R,I,b;for(i=-1;i<1;i+=.06,puts(""))for(r=-2;I=i,(R=r)<1;
r+=.03,putchar(n+31))for(n=0;b=I*I,26>n++&&R*R+b<4;I=2*R*I+i,R=R*R-b+r);}
#+end_src

#+begin_notes
We're so used to working in "a more computationally efficient space".

Maybe you can guess what this does? Hint: it's from the mid-90s.

Check out the "R*R+b<4" part.
#+end_notes

** Monoid Homomorphism example

The usual example is string -> int (length).

Sometimes the monoid is buried. Often the "surface" monoid is a monoid we can't
express very well in C++. Like function composition.

LCG example.

** Regular expressions

http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html

** Tournaments

** Diagrams


* My favourite quote

"Discovery consists of seeing what everybody has seen, and thinking what nobody
has thought."

Albert Szent-Gy√∂rgyi. (Hungarian Nobel Laureate in Medicine, 1937)

#+begin_notes
I hope that after this talk you can look at your code in a new way and think
what you have not thought before.
#+end_notes

* References
/Cultivating Instinct/ Katrina Owen
https://www.youtube.com/watch?v=Q1Tlo4VnQrA
