#    -*- mode: org -*-
#+OPTIONS: reveal_center:t reveal_progress:t reveal_history:t reveal_control:t
#+OPTIONS: reveal_mathjax:t reveal_rolling_links:nil reveal_keyboard:t reveal_overview:t num:nil
#+OPTIONS: reveal_width:1600 reveal_height:900
#+OPTIONS: toc:nil <:nil timestamp:nil email:t reveal_slide_number:"c/t"
#+REVEAL_MARGIN: 0.1
#+REVEAL_MIN_SCALE: 0.5
#+REVEAL_MAX_SCALE: 2.5
#+REVEAL_TRANS: none
#+REVEAL_THEME: blood
#+REVEAL_HLEVEL: 1
#+REVEAL_EXTRA_CSS: ./presentation.css
#+REVEAL_ROOT: ../reveal.js/

#+TITLE: Identifying Monoids
#+AUTHOR: Ben Deane
#+EMAIL: bdeane@quantlab.com
#+DATE: May 2019

#+REVEAL_HTML: <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
#+REVEAL_HTML: <script type="text/javascript" src="./presentation.js"></script>

* Title slide settings                                             :noexport:
#+BEGIN_SRC emacs-lisp
(setq org-re-reveal-title-slide
(concat "<h2>%t</h2>"
"<h3>Exploiting Compositional Structure in Code</h3>"
"<div class='vertspace2'></div>"
"<img src=\"./wood.png\"/>"
"<p>\\(\\left \\{ \\mathbb{Z}, \\times, 1 \\right \\}\\)</p>"
"<div class='vertspace2'></div>"
"<h4>%a / <a href=\"http://twitter.com/ben_deane\">@ben_deane</a>"
" / C++Now / Aspen, CO / %d</h4>"))
#+END_SRC

* Let's get this out of the way.

A monoid is NOT the same thing as a monad.

#+begin_notes
Some of you already know this. (How many people know all about monoids?)

Some people, online or wherever, may be confused, so I wanted to be clear.

This isn't a talk with a lot of category theory. I'm probably going to say lots
of things that mathematicians will take issue with. I'm going to try ground this
talk in examples.
#+end_notes

* Why

Why are monoids important?

Why is "abstract mathematics" important for programming?

#+begin_notes
(Tell the Simeon story.)

There are people who think this kind of mathematics has no place in programming.
(They don't seem to mind other kinds of maths like linear algebra.) They are
looking at things the wrong way.

When we program, we're doing maths whether we know it or not, and it helps us to
realize that. Composition is the essence of programming architecture. Abstract
algebra is the framework for ideas of composition.

You can program without maths, just like you can bake without knowing chemistry.
But you're doing it anyway. You already have an intuition for it.

Abstract algebra is to programming what calculus is to modelling the real world.
#+end_notes

* A quick code review

#+begin_src c++
void RepositionListItem(int drag_start_idx, int drop_idx) {
  // grab the dragged item
  Item* item = list_items_[drag_start_index];

  // move the rest down
  for (auto i = drag_start_idx + 1; i < list_items_.size(); ++i) {
    list_items_[i-1] = list_items_[i];
  }
  list_items_.pop_back();

  // re-insert at the drop index
  list_items_.insert(item, list_items_.begin() + drop_idx);
}
#+end_src

#+ATTR_REVEAL: :frag (appear)
 - "This is (obviously?) a rotate."
 - And there's a bug here. Is ~drag_start_idx~ ~>~ ~drop_idx~?

#+begin_notes
What would you suggest for this code review?

What is this code doing?

Do you see any problems?
#+end_notes

* How did we know that?

Expertise.

 - Hard to say how
 - Difference in perception
   - Selectivity of attention
   - Units of perception
   - Unconscious search strategies
 - Speed of processing

#+begin_notes
These are the hallmarks of expertise. A difference in what we pay attention to.
A difference in the chunk size of things we perceive. A difference in the search
patterns we pursue. And a huge speed difference.

Everyone here is a C++ expert. We probably can't really explain how we knew the
problems. You just had a "spidey sense". A C++ novice looking at the code may
not even know where to begin.
#+end_notes

* How brains work

1. See lots of examples with lots of variation. Some variation is relevant,
   some is not.
1. Figure out which variation is relevant, and classify.
1. Trial and error: rinse, repeat...
1. Result after time: "instinctual" expertise

#+ATTR_REVEAL: :frag (appear)
So let's get going.

#+begin_notes
We can say how we got here, because this is what brains do. We don't learn by
applying abstract rules. We learn by this process.

So in this talk, mostly I'm going to show lots of different monoids, so that we
get an intuition about how to recognize them; each brain experiencing this talk
will form its own pattern-recognition pathways. This is what brains do (very
well).

When we have that sense, then it can be useful to fill in more theory.
#+end_notes

* What is a monoid?

* Why is it important to recognize them?

Architecture.
A means to talk about what's happening in our code.

It's not about functional programming, it's not about abstraction for its own
sake.

Computational sympathy.

* Abstraction

"Being abstract is something profoundly different from being vague â€¦ The purpose
of abstraction is not to be vague, but to create a new semantic level in which
one can be absolutely precise."

--EWD

* Design Patterns

Compare Design Patterns.

There are people who get the wrong end of the stick about this. There are people
who, for example, tweet that they're hiring, but say things like "use of Design
Patterns is a negative".

Design Patterns came out in 1995. The implementations in it are of their time.
They represent a Java-style, late 90s, heavy-OO, dynamic dispatch style of
implementation. That's not the lasting legacy of the book.

If we're talking about code and I say to you, "I think we could solve this with
a visitor pattern", I'm not saying "let's open the Gang of Four book and
implement all this machinery to implement dynamic double-dispatch." I'm saying
"I think we could benefit from the ability to easily add behaviours over types."
And we can implement that using all the tools we have in our toolbox and make it
perform arbitrarily well according to our needs.

* The power of abstraction

We can talk about our code's needs rather than how to implement those needs

* Late night coding with Simeon

You only have a binary operation to combine objects
You have a list of objects to combine
Show a raw loop
Realize it's an accumulate - we have a monoid!

* Alex Stepanov

Saw/realised the structure of monoids/semigroups while sick

* Why?

When we recognize monoids, we gain the ability to separate concerns.

If we write code as raw loops, we commingle the business logic with the code
that handles control flow.

Instead of having to learn anew how each computation in our code works, a user
of our code/library just has to learn one idea: that of accumulation. They don't
have to puzzle out what each loop is doing.

* The obvious monoids

* Addition & Multiplication

Many things that are "number-like"
ints, floats, vectors, matrices, complex numbers

* How to Identify a monoid
 - closed
 - associative
 - identity

Note: not commutative

Intuition for associativity: combining things on the left doesn't interfere with
combining things on the right.

* Min and Max

Sometimes not monoids (min) but still semigroups

* Optional

Make a semigroup into a monoid!

* Strings and vectors

All things concatenation

* Booleans

and, or, xor

* Sets and Maps

Monoids on their value types

* Structs, pairs and tuples

Product types are monoidal if their constituents are
This is useful for accumulating effects
cf. Writer monad
http://blog.sigfpe.com/2009/01/haskell-monoids-and-their-uses.html

* Functions

Monoidal on their outputs
cf. maps

* Tree structures

"Normal" monoids have two operations:
 - one for combining with identity
 - one for combining with value

If we look at a tree structure as a sum type, we can extend this to:
 - one for combining each type of value

And we can run functions over tree structures, accumulating the values. Just
like std::accumulate, this gives us the power to separate the meaning of what
we're doing from the control flow of how we're doing it.

Most of the algorithms in the STL deal with linear sequences. And that's most of
what we handle. But quite often we handle treelike structures. It's much more
likely then that we'll fail to see the essential computation that's going on and
fall back on a raw loop because we think algorithms can't deal with what we're
doing. If we think in terms of monoids, we can get that separation of control
flow from logic and we can often use an accumulate-like algorithm to separate
the control flow.

* Endofunctions

Functions from A to A
Processes evolving in time
std::iota
std::iterate
ranges

Examples:

 - Eller's algo for maze generation - plain std::accumulate (linear data dependence)
   or partial_sum for intermediate output (good range example?)

 - RNG - LCG is a linear recurrence relation f :: a -> a
   represent as a matrix -> function composition is raising to nth power (log n)
   can "fast forward" RNG in log time because it's a monoid
https://www.nayuki.io/page/fast-skipping-in-a-linear-congruential-generator

Research:

https://meetingcpp.com/blog/items/ranges-for-numerical-problems-402.html
https://www.youtube.com/watch?v=13r9QY6cmjc
http://people.math.gatech.edu/~ecroot/recurrence_notes2.pdf

* Futures

when_any and never
UI applications

* Stronger than monoids
Commutativity
Existence of an inverse

* Accumulate vs reduce

Reduce requires commutativity for vectorization
Data-level parallelism at war with function-level parallelism
(parallelism vs concurrency)

* Balanced reduction

* Incremental computation

* Bigger applications

** Serialization
Monoid-like, but with varying types

** Profiling
Another kind of serialization

** Statistics
Keeping a mean
Keeping a median
Top n
Histograms

** Probabilistic algorithms
"Fantastic algorithms and where to find them"
"Add ALL the things!"

Hyperloglog
Count min-sketch

** Config

JSON objects, databases, configuration blobs, sets of command-line flags
Protocol buffers

We "reinvent" monoids all the time without realizing it! Most of the time when
we deal with these kinds of things, we don't think about their monoidal nature.

https://mail.haskell.org/pipermail/haskell-cafe/2009-January/053709.html

** Parsers

Parsers are monoids under alternation. The identity is the parser that always
fails. This is a common pattern if you have an operation that can fail.

cf. when_any
cf. optional

** Monoid homomorphisms

A function that preserves the monoid structure. If A and B are monoids under
some operations, then f :: A -> B is a monoid homomorphism if it preserves the
structure.

e.g.
 - strings are monoids under concatenation.
 - integers are monoids under addition.

string length is a monoid homomorphism.

** Why use monoid homomorphisms?

- to get into a space that is easier to reason about
- to be able to do more
- for performance
- all of the above

** For perf?

We're always doing things for performance reasons of course.
We're often computing things in a "different space" for perf reasons.

e.g.

In vector spaces, we can avoid square roots when computing magnitudes because we
can compare to a precomputed magnitude in "squared space" instead.

In vector spaces, we measure angles between vectors by comparing with
precomputed cosine constants rather than doing an inverse trig function.

** Ofuscated example

#+begin_src c
main(n){float r,i,R,I,b;for(i=-1;i<1;i+=.06,puts(""))for(r=-2;I=i,(R=r)<1;
r+=.03,putchar(n+31))for(n=0;b=I*I,26>n++&&R*R+b<4;I=2*R*I+i,R=R*R-b+r);}
#+end_src

#+begin_notes
We're so used to working in "a more computationally efficient space".

Maybe you can guess what this does? Hint: it's from the mid-90s.

Check out the "R*R+b<4" part.
#+end_notes

** Monoid Homomorphism example

The usual example is string -> int (length).

Sometimes the monoid is buried. Often the "surface" monoid is a monoid we can't
express very well in C++. Like function composition.

LCG example.

** Regular expressions

http://blog.sigfpe.com/2009/01/fast-incremental-regular-expression.html

** Tournaments

** Diagrams


* My favourite quote

"Discovery consists of seeing what everybody has seen, and thinking what nobody
has thought."

Albert Szent-GyÃ¶rgyi. (Hungarian Nobel Laureate in Medicine, 1937)

#+begin_notes
I hope that after this talk you can look at your code in a new way and think
what you have not thought before.
#+end_notes

* References
/Cultivating Instinct/ Katrina Owen
https://www.youtube.com/watch?v=Q1Tlo4VnQrA
